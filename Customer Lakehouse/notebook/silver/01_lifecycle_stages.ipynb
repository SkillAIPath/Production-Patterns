# üìå Logging Setup (Always at the top)
import logging
try:
    dbutils.widgets.text("log_level", "INFO")
    log_level = dbutils.widgets.get("log_level")
except:
    log_level = "INFO"

logging.basicConfig(level=log_level, format="%(asctime)s - %(name)s - %(levelname)s - %(message)s")
logger = logging.getLogger(__name__)
logger.info(f"Notebook started with log level: {log_level}")

# üìå Lifecycle Stage Derivation Logic

logger.info("Loading Bronze Tables...")

customers_bronze = spark.table("bronze.customers")
transactions_bronze = spark.table("bronze.transactions")

# üõ†Ô∏è Debug: Validate Customers + Transactions load
customers_bronze.select("Region", "SubscriptionPlan").distinct().show()
transactions_bronze.select("PaymentMethod").distinct().show()
logger.info("Bronze Tables loaded successfully.")

# Derive Lifecycle Stages based on LastTransactionDate
from pyspark.sql.functions import col, when, max as max_, expr

logger.info("Deriving Customer Lifecycle Stages...")

customer_txn_status = (
    transactions_bronze.groupBy("CustomerID")
    .agg(max_("TransactionDate").alias("LastTransactionDate"))
)

customer_lifecycle = (
    customers_bronze.join(customer_txn_status, "CustomerID", "left")
    .withColumn("DaysSinceLastTxn", expr("datediff(current_date(), LastTransactionDate)"))
    .withColumn("LifecycleStage",
        when(col("DaysSinceLastTxn") <= 30, "Active")
        .when((col("DaysSinceLastTxn") > 30) & (col("DaysSinceLastTxn") <= 60), "At Risk")
        .when(col("DaysSinceLastTxn") > 60, "Churned")
        .otherwise("Lead")  # No transactions
    )
)

# üõ†Ô∏è Debug: Validate Lifecycle Stages
customer_lifecycle.groupBy("LifecycleStage").count().show()
logger.info("Lifecycle Stages derived successfully.")

# Write to Silver
customer_lifecycle.write.format("delta").mode("overwrite").saveAsTable("silver.customers_lifecycle")
logger.info("Lifecycle Stage table written to silver.customers_lifecycle.")
